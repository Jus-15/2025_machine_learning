# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xhbywsTIr-xY-kSu9GmNnvL2QAdQ9BMK
"""

import numpy as np
import matplotlib.pyplot as plt

def runge(x):
    # f(x) = 1 / (1 + 25 x^2)
    return 1.0 / (1.0 + 25.0 * x**2)

rng1 = np.random.default_rng()

N = 2000                     # 2000個樣本
x_all = rng1.uniform(-1.0, 1.0, size=(N, 1)) # 均勻隨機取樣於 [-1, 1]
y_all = runge(x_all)


n_train, n_val = 1200, 600
id = rng1.permutation(N)          # 打亂索引以隨機切分
train_id = id[:n_train]
val_id = id[n_train:n_train + n_val]
test_id = id[n_train + n_val:]

x_train, y_train = x_all[train_id], y_all[train_id]
x_val, y_val   = x_all[val_id],  y_all[val_id]
x_test, y_test  = x_all[test_id], y_all[test_id]


H1 = 10  # 第二層神經元個數
H2 = 10  # 第三層神經元個數


def sigmoid(x):
    return 1.0 / (1.0 + np.exp(-x))

def Weight_Initialization(m, n, generator):
    limit = 5
    W = generator.uniform(-limit, limit, size=(m, n))
    b = generator.uniform(-limit, limit, size=(m, 1))
    return W, b

# 參數
rng2 = np.random.default_rng()
W2, b2 = Weight_Initialization(H1, 1, rng2)  # 第一層: 1 -> H1
W3, b3 = Weight_Initialization(H2, H1, rng2)  # 第二層: H1 -> H2
W4, b4 = Weight_Initialization(1, H2, rng2)  # 第三層: H2 -> 1

def forward_pass(x, W2, b2, W3, b3, W4, b4):
    # 第一層
    z2 = W2 @ x + b2
    a2 = sigmoid(z2)

    # 第二層
    z3 = W3 @ a2 + b3
    a3 = sigmoid(z3)

    # 第三層 (輸出層)
    z4 = W4 @ a3 + b4
    y_hat = z4
    return y_hat, (a2, a3)

def MSE(y_hat, y):
    #誤差 MSE
    return np.mean((y_hat - y)**2)


# 使用mini-batch
epochs = 1000      # 訓練輪數
batch_size = 4    # 小批次大小
Learn_Rate = 0.05   # 學習率

train_losses = []
val_losses = []

# 訓練
for ep in range(epochs):
    # 打亂訓練資料索引
    p = rng1.permutation(len(x_train))

    for i in range(0, len(p), batch_size):
        idxb = p[i:i + batch_size]
        xb = x_train[idxb].T      # (1, B)
        yb = y_train[idxb].T      # (1, B)
        B  = xb.shape[1]       #避免最後一次不夠batch_size

        # 向前傳播
        y_hat, (a2, a3) = forward_pass(xb, W2, b2, W3, b3, W4, b4)

        # 反向傳播
        # dL/dyhat = 2*(yhat - y)/B
        dL_dyhat = 2.0 * (y_hat - yb) / B

        # 第四層
        # yhat = z4
        dL_dz4 = dL_dyhat
        dL_dW4 = dL_dz4 @ a3.T
        dL_db4 = np.sum(dL_dz4, axis=1, keepdims=True)


        # 第三層
        dL_dz3 = (W4.T @ dL_dz4) * (a3 * (1.0 - a3))
        dL_dW3 = dL_dz3 @ a2.T
        dL_db3 = np.sum(dL_dz3, axis=1, keepdims=True)


        # 第二層
        dL_dz2 = (W3.T @ dL_dz3)  * (a2 * (1.0 - a2))
        dL_dW2 = dL_dz2 @ xb.T
        dL_db2 = np.sum(dL_dz2, axis=1, keepdims=True)

        # 更新參數
        W4 -= Learn_Rate * dL_dW4
        b4 -= Learn_Rate * dL_db4
        W3 -= Learn_Rate * dL_dW3
        b3 -= Learn_Rate * dL_db3
        W2 -= Learn_Rate * dL_dW2
        b2 -= Learn_Rate * dL_db2

    # Train/Val 的 MSE
    yhat_tr, (A1,A2) = forward_pass(x_train.T, W2, b2, W3, b3, W4, b4)
    yhat_va, (A3,A4) = forward_pass(x_val.T,  W2, b2, W3, b3, W4, b4)
    train_losses.append(MSE(yhat_tr, y_train.T))
    val_losses.append(MSE(yhat_va,  y_val.T))

# 評估
y_pred_test, (A5,A6) = forward_pass(x_test.T, W2, b2, W3, b3, W4, b4)
MSE_train = train_losses[-1]
MSE_val   = val_losses[-1]
MSE_test  = MSE(y_pred_test, y_test.T)
max_err_test = np.max(np.abs(y_pred_test - y_test.T))

print(f"Train MSE: {MSE_train:.6f}")
print(f"Val  MSE: {MSE_val:.6f}")
print(f"Test  MSE: {MSE_test:.6f}")
print(f"Test  Max Error: {max_err_test:.6f}")

# 作圖
# (a) 真值 vs. NN 預測
xx = np.linspace(-1, 1, 400).reshape(-1, 1)
yy_true = runge(xx)
yy_pred, (A7,A8) = forward_pass(xx.T, W2, b2, W3, b3, W4, b4)
yy_pred = yy_pred.T

plt.figure(figsize=(8, 5))
plt.plot(xx, yy_true, label="True f(x)")
plt.plot(xx, yy_pred, label="NN prediction")
plt.scatter(x_train, y_train, s=8, alpha=0.3, label="Train points")
plt.title("Runge Function Approximation")
plt.xlabel("x"); plt.ylabel("y"); plt.legend(); plt.grid(True, alpha=0.2)
plt.tight_layout()
plt.show()

# (b) 訓練/驗證損失曲線
plt.figure(figsize=(8, 5))
plt.plot(np.arange(1, epochs + 1), train_losses, label="Train MSE")
plt.plot(np.arange(1, epochs + 1), val_losses,   label="Val MSE")
plt.xlabel("Epoch"); plt.ylabel("MSE Loss")
plt.title("Training / Validation Loss")
plt.legend(); plt.grid(True, alpha=0.2)
plt.tight_layout()
plt.show()